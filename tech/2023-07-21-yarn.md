----------------------------------------------------------------------------------------
layout: post title: "An informal recollection of migrating a monorepo from node_modules
to .pnp.cjs" categories: tech date: 2023-07-21
---------------------------------------------------------------------------------------

A lot:

- updating shared dependencies
- explicitly defining dependencies
- unifying on a single version of webpack
- gulp??
- fixing tests
- making all those changes and not causing downtime for developers

----------------------------------------------------------------------------------------

## Preface

Prior to this project, I didn't know anything about [Yarn](https://yarnpkg.com/) or
frontend build systems in general. Frontend "stuff" has never been my jam, but improving
build experience and efficiency definitely is. With that in mind, please pardon my
ignorance if I use some incorrect terminology throughout this article, and please let me
know if any edits should be made to improve clarity!

A few people had made multiple partial strides to help get this closer to the finish
line prior to my involvement, but it was clearly going to take some focused effort to
connect the dots and get to a point where the switch could be fully flipped (spoiler
alert: it's essentially impossible to incrementally introduce Plug'n'Play to a monorepo,
it's an all-or-nothing operation at the end of the day). Despite the large hurdles in
the way, the performance gains and other QoL improvements promised at the end of the
tunnel were too good to leave on the table. Plus, all the melting Intel MacBooks were
depending on us!

## Context and status quo

### What is Yarn Plug'n'Play?

[Yarn Plug'n'Play](https://yarnpkg.com/features/pnp), hereby referenced as PnP, works by
"[telling] Yarn to generate a single Node.js loader file in place of the typical
`node_modules` folder. This loader file, named `.pnp.cjs`, contains all information
about your project's dependency tree, informing your tools as to the location of the
packages on the disk and letting them know how to resolve require and import calls."[^0]

So, instead of resolving imports directly from the `node_modules` folder where they've
been fully decompressed and installed, `.pnp.cjs` contains what is essentially a map
from a package reference to its location right within the zip file of the package within
Yarn's package cache. Here's a snippet from [`berry/.pnp.cjs`
](https://github.com/yarnpkg/berry/blob/master/.pnp.cjs) which might better visualize
what's happening:

```
    ["callsites", [\
      ["npm:3.0.0", {\
        "packageLocation": "./.yarn/cache/callsites-npm-3.0.0-4966cb90f4-40e3cb2027.zip/node_modules/callsites/",\
        "packageDependencies": [\
          ["callsites", "npm:3.0.0"]\
        ],\
        "linkType": "HARD"\
      }]\
    ]],\
```

So, when `callsites` is referenced, Yarn knows to resolve the import from right within
the `zip` file! No need to decompress and install the cache to the `node_modules`
directory.

### Why would we want to use PnP anyway?

Here's a quick gist of what we were dealing with prior to the switch to PnP.

- A multi-language monorepo with many services, each with their own `package.json`, with
  a root `package.json` which points to all the workspaces within the repo.
- Most services use the same version of common dependencies, but this isn't always a
  guarantee. In some services, outdated versions of webpack were being used which didn't
  support PnP out of the box. There were also a bunch of other major version dependency
  upgrades.
- The build environment is a Docker container running through Docker Desktop on macOS
- Build time for one of the larger services would take **approximately 13 minutes** when
  using a [bind mount](https://docs.docker.com/storage/bind-mounts/) from host to
  container for the container's working tree. Build time _could_ be noticeably decreased
  by using a volume instead of a bind mount for the working tree, but this introduced an
  intermediate "sync" step between host and container for the majority of developer
  operations (not just builds) in order to get the working tree into the container. One
  of the major downsides of this is **slow container creation**, resulting in many
  developers treating their containers as pets, not cattle[^0], understandably so.
- Building the "world" when using a bind mount would result in a `node_modules`
  directory of multiple GBs **which would have to hop across the host to container
  boundary during the build, resulting in a ton of disk I/O bottleneck.** Bind mount
  performance actually performed worse than volume performance, even _with_ the volume
  sync step!

## Getting started

Before diving in, there were some guides available on the subject of moving from
node_modules to PnP. Some of which were internal runbooks that engineers had put
together, outlining what package upgrades and config changes would be necessary in order
to get our packages in a PnP-supportable state. This pre-work was invaluable, as I was
able to hit the ground running and see their efforts through across the whole codebase.

Along with internal help, Yarn itself provided some "recipes" to help with the
transition. I sent of a message in the Yarn discord looking for some more help before I
went off and did my own thing:

> szehnder â€” 08/12/2022 9:38 AM ðŸ‘‹ hello! I'm currently working on migrating a monorepo
> over to using PnP (using yarn v3 fyi). The [Hybrid PnP + node_modules mono-repo](
> https://yarnpkg.com/getting-started/recipes/#hybrid-pnp--node_modules-mono-repo)
> recipe is helpful, but I'm wondering if there is a recommended path for a hybrid
> approach where PnP is opt-in, rather than the other way around like the above recipe
> suggests. Thanks in advance!

## The gameplan

I didn't hear back, so I had to do some thinking about how to go about doing this
without causing downtime for our devs. If PnP can't be opt-in, then the switch to PnP
will need to happen in one fell swoop, which is much easier said than done! This is what
I came up with:

> szehnder â€” 08/29/2022 11:56 AM After some searching, it seems like there isn't strong
> support for linking PnP-based packages to node-modules-based packages, which makes
> sense. I have instead opted to do the following, in case it helps anyone else:
>
> - switch .yarnrc.yml over to nodeLinker:pnp
> - attempt to yarn install and subsequently build atomic components within the monorepo
>   with PnP
> - after making necessary tweaks to successfully build, switch back to nodeLinker:
>   node-modules and yarn install and build with the changes I made for PnP, just to
>   verfy it works in node-modules world as well
> - put up a diff for the atomic component, not adding .pnp.cjs and keeping the
>   nodeLinker as node-modules
>
> once all of these piecemeal changes have been made and committed, I'll commit the
> nodeLinker:pnp change and the .pnp.cjs file, and we should ideally be able to make a
> somewhat painless switch over to PnP
>
> I have written a helper script that toggles my environment between one that uses
> .pnp.cjs and node_modules/, so i am not spending a ton of time waiting for either to
> repopulate when switching my nodeLinker between the two

Thinking more about this now, I don't know if it makes sense to not support
cross-linking PnP- and node_modules-backed packages. Knowing more about the system now,
it doesn't seem like there would be any technical limitation to allowing this type of
behavior, other than maybe some performance hit when trying to resolve packages in both
systems. But anyway...

The process outlined above really did end up being the main workflow for handling the
migration -- run my `pnp-toggle` script, try and build a package, resolve failures that
pop up through a myriad of different fixes, once it built with PnP, run `pnp-toggle` and
try and build it with node_modules to see if it still worked. Then, merge the changes
_without_ switching the repo over to PnP as the nodeLinker. Devs didn't notice any
difference, the only thing affected was my MacBook's CPU[^1].

## The experience

need to get it done quick since new stuff slips in all the time

## The results

- 13 minutes down to 2.5 minutes!
- "syncless" default container behavior! you get a bind mount, you get a bind mount

----------------------------------------------------------------------------------------

Have others gone through a similar migration? Did you do things differently that
resulted in a less painful process? I'm curious to know what others ran into when doing

----------------------------------------------------------------------------------------

### Footnotes

[^0]: [https://yarnpkg.com/features/pnp#how-does-it-work](https://yarnpkg.com/features/pnp#how-does-it-work)
[^1]:[The history of pets vs cattle](
http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/) [^2]: By
the end of this effort, my MacBook CPU was legitimately cooked. Things started breaking
in very weird ways, and diagnostics at the Genius Bar reported back that it had seen
sustained high temperature events very frequently. 8 hours of compilation a day can do
that I guess.
